// Detects potential malware in the codebase using a fine-tuned LLM.

'use server';

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const MalwareDetectionInputSchema = z.object({
  codebase: z.string().describe('The codebase to scan for malware.'),
});
export type MalwareDetectionInput = z.infer<typeof MalwareDetectionInputSchema>;

const MalwareDetectionOutputSchema = z.object({
  hasMalware: z.boolean().describe('Whether malware was detected in the codebase.'),
  details: z.string().describe('Details about the detected malware, if any.'),
});
export type MalwareDetectionOutput = z.infer<typeof MalwareDetectionOutputSchema>;

export async function detectMalware(input: MalwareDetectionInput): Promise<MalwareDetectionOutput> {
  return detectMalwareFlow(input);
}

const malwareDetectionPrompt = ai.definePrompt({
  name: 'malwareDetectionPrompt',
  input: {schema: MalwareDetectionInputSchema},
  output: {schema: MalwareDetectionOutputSchema},
  prompt: `You are a security expert specializing in malware detection.

You will analyze the provided codebase for potential malware, including trojan horses and viruses.
Focus on identifying suspicious patterns, file uploads, new dependencies, and code comments.

Codebase:
{{codebase}}

Based on your analysis, determine if the codebase contains malware and provide details.
Be certain that the detected malware is actually present in the code before setting the hasMalware output field to true.

Output in JSON format:
{ \
  "hasMalware": true/false,
  "details": "Details about the detected malware, if any."
}
`,
});

const detectMalwareFlow = ai.defineFlow(
  {
    name: 'detectMalwareFlow',
    inputSchema: MalwareDetectionInputSchema,
    outputSchema: MalwareDetectionOutputSchema,
  },
  async input => {
    const {output} = await malwareDetectionPrompt(input);
    return output!;
  }
);
